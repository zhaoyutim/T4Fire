
2021-12-03 13:13:50.685942: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Model: "vit-b16"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_1 (InputLayer)            [(None, 10, 45)]     0
__________________________________________________________________________________________________
patch_encoder (PatchEncoder)    (10, 768)            7680        input_1[0][0]
__________________________________________________________________________________________________
dense (Dense)                   (None, 10, 768)      35328       input_1[0][0]
__________________________________________________________________________________________________
tf.__operators__.add (TFOpLambd (None, 10, 768)      0           patch_encoder[0][0]
                                                                 dense[0][0]
__________________________________________________________________________________________________
Transformer/encoderblock_0 (Tra ((None, 10, 768), (N 7087872     tf.__operators__.add[0][0]
__________________________________________________________________________________________________
Transformer/encoderblock_1 (Tra ((None, 10, 768), (N 7087872     Transformer/encoderblock_0[0][0]
__________________________________________________________________________________________________
Transformer/encoderblock_2 (Tra ((None, 10, 768), (N 7087872     Transformer/encoderblock_1[0][0]
__________________________________________________________________________________________________
Transformer/encoderblock_3 (Tra ((None, 10, 768), (N 7087872     Transformer/encoderblock_2[0][0]
__________________________________________________________________________________________________
Transformer/encoderblock_4 (Tra ((None, 10, 768), (N 7087872     Transformer/encoderblock_3[0][0]
__________________________________________________________________________________________________
Transformer/encoderblock_5 (Tra ((None, 10, 768), (N 7087872     Transformer/encoderblock_4[0][0]
__________________________________________________________________________________________________
Transformer/encoderblock_6 (Tra ((None, 10, 768), (N 7087872     Transformer/encoderblock_5[0][0]
__________________________________________________________________________________________________
Transformer/encoderblock_7 (Tra ((None, 10, 768), (N 7087872     Transformer/encoderblock_6[0][0]
__________________________________________________________________________________________________
Transformer/encoderblock_8 (Tra ((None, 10, 768), (N 7087872     Transformer/encoderblock_7[0][0]
__________________________________________________________________________________________________
Transformer/encoderblock_9 (Tra ((None, 10, 768), (N 7087872     Transformer/encoderblock_8[0][0]
__________________________________________________________________________________________________
Transformer/encoderblock_10 (Tr ((None, 10, 768), (N 7087872     Transformer/encoderblock_9[0][0]
__________________________________________________________________________________________________
Transformer/encoderblock_11 (Tr ((None, 10, 768), (N 7087872     Transformer/encoderblock_10[0][0]
__________________________________________________________________________________________________
Transformer/encoder_norm (Layer (None, 10, 768)      1536        Transformer/encoderblock_11[0][0]
__________________________________________________________________________________________________
head (Dense)                    (None, 10, 2)        1538        Transformer/encoder_norm[0][0]
==================================================================================================
Total params: 85,100,546
Trainable params: 85,100,546
Non-trainable params: 0
__________________________________________________________________________________________________
training in progress
Epoch 1/50
 3/10 [========>.....................] - ETA: 1s - loss: 0.1060 - accuracy: 0.8228
10/10 [==============================] - 14s 177ms/step - loss: 0.0318 - accuracy: 0.9468
Epoch 2/50
10/10 [==============================] - 2s 173ms/step - loss: 0.0012 - accuracy: 0.9999
Epoch 3/50
10/10 [==============================] - 2s 166ms/step - loss: 0.0242 - accuracy: 0.9931
Epoch 4/50
10/10 [==============================] - 2s 168ms/step - loss: 0.0249 - accuracy: 0.9807
Epoch 5/50
10/10 [==============================] - 2s 171ms/step - loss: 0.0229 - accuracy: 0.9766
Epoch 6/50
10/10 [==============================] - 2s 164ms/step - loss: 0.0070 - accuracy: 0.9913
Epoch 7/50
10/10 [==============================] - 2s 167ms/step - loss: 4.8630e-05 - accuracy: 1.0000
Epoch 8/50
10/10 [==============================] - 2s 171ms/step - loss: 1.6560e-06 - accuracy: 1.0000
Epoch 9/50
10/10 [==============================] - 2s 170ms/step - loss: 0.0129 - accuracy: 0.9891
Epoch 10/50
